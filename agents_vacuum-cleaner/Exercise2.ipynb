{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 2 - Agente Reativo Simples em Ambiente Completamente Observável"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implemente um novo agente reativo simples, mas agora com a vantagem de conhecer o ambiente (completamente observável). Você deve ser capaz de colocar o agente no seu simulador do exercício anterior e comparar o desempenho seguindo a mesma metodologia do exercício anterior. Compare o desempenho dos dois agentes (o deste exercício e o do anterior) neste simulador. Para o comparativo, alguns critérios do PEAS serão alterados.\n",
    "\n",
    "- **Medida de Desempenho**: A medida de desempenho oferece o prêmio de um ponto para cada quadrado limpo em cada período de tempo ao longo de uma duração de mil períodos de tempo. Entretanto, diferentemente do exercício anterior, agora penaliza em um ponto qualquer operação de movimento que não seja NoOp e Limpar.\n",
    "- **Conhecimento a priori**: A geografia do ambiente é conhecida a priori (Figura 2.2), mas a distribuição da sujeira e a posição inicial do agente não são previamente conhecidas. O ambiente para o agente é completamente observável. A aspiração limpa o quadrado atual. As ações esquerda e direita movem o agente para a esquerda e para a direita, exceto quando isso tenta levar o agente para fora do ambiente; nesse caso, o agente permanece onde está. \n",
    "- **Ações do agente**: Esquerda, Direita, Limpar e NoOp (fazer nada).\n",
    "- Percepções: O agente percebe corretamente sua posição e se esta posição contém sujeita.\n",
    "- **Ambiente**: mundo do aspirador de pó com apenas duas salas. Estas que por sua vez, podem estar limpas ou não conforme o tempo passa. A sujeira pode surgir de modo espontâneo para fins de simulação. \n",
    "\n",
    "Agora, implemente um agente reativo simples para este ambiente. Execute o simulador de ambiente com este agente para todas as configuraçoes iniciais possíveis de sujeira e posições do agente. Registre a pontuação  de desempenho dos dois agentes para cada configuração e suas pontuações médias globais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "Para começar vamos importar algumas funções que vamos utilizar no código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classe: Enviroment\n",
    "A classe Enviroment vai representar o ambiente, foi criada com a intenção de funcionar para n salas. Nessa classe foram implementadas as funções da criação do próprio ambiente e da criação de sujeira ao longo do tempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Enviroment:\n",
    "    FLOOR_STATE = {\"clean\": 0, \"dirty\": 1}\n",
    "    \n",
    "    def __init__ (self, size: int):\n",
    "        self.rooms = [0] * size\n",
    "    \n",
    "    # Função que inicia as salas de maneira randômica.\n",
    "    def init_randomly(self, dirtyRate: int):\n",
    "        for i in range(len(self.rooms)):\n",
    "            if r.randint(0, 100) < dirtyRate:\n",
    "                self.rooms[i] = Enviroment.FLOOR_STATE[\"dirty\"]\n",
    "            else:\n",
    "                self.rooms[i] = Enviroment.FLOOR_STATE[\"clean\"]\n",
    "    \n",
    "    # Função que inicia as salas de acordo com o array desejado.\n",
    "    def init_rooms(self, rooms: list):\n",
    "        self.rooms = rooms.copy()\n",
    "\n",
    "    # Função que suja as salas de maneira aleatória(usada no loop para sujar as salas de acordo com o tempo).\n",
    "    # dirtyRate: Variável que vai de 0 a 100 que representa a porcentagem de chance de sujar cada sala.\n",
    "    def rand_dirty_rooms (self, dirtyRate: int):\n",
    "        for i, room in enumerate(self.rooms):\n",
    "            if(room == Enviroment.FLOOR_STATE[\"clean\"] and r.randint(0, 100) < dirtyRate):\n",
    "                self.rooms[i] = Enviroment.FLOOR_STATE[\"dirty\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Classe: Agent\n",
    "A classe agent representará o agente e possui a função que determina como o mesmo irá se comportar dado o ambiente. Ele possui as ações de NoOp(ficar pararo caso bater na parede), limpar(caso a sala que está esteja suja), direita e esquerda(para andar pelas salas). Como nesse exercício nós teremos dois tipos de agente, a função action é preenchida em cada agente específico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    ACTIONS = {\"NoOp\": 0, \"clean\": 2, \"right\": 1, \"left\": -1}\n",
    "    \n",
    "    def __init__ (self):\n",
    "        self.position = None\n",
    "        \n",
    "    # Função que muda a posição inicial.\n",
    "    def initial_position(self, initial_position: int):\n",
    "        self.position = initial_position\n",
    "\n",
    "    # Função que representa como o agente vai agir dado o ambiente\n",
    "    def action (self, env: Enviroment):\n",
    "        pass\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classe: Smart_agent\n",
    "A classe Smart_agent vai representar a ação do agente reativo simples em ambiente completamente observável"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Smart_agent(Agent):\n",
    "    def __init__ (self):\n",
    "        Agent.__init__(self)\n",
    "    \n",
    "    # Função que representa como o agente vai agir dado o ambiente\n",
    "    def action (self, env: Enviroment):\n",
    "        # Checar se a sala atual está suja e se estiver, limpar.\n",
    "        if env.rooms[self.position] == Enviroment.FLOOR_STATE[\"dirty\"]:\n",
    "            env.rooms[self.position] = Enviroment.FLOOR_STATE[\"clean\"]\n",
    "            \n",
    "            return Agent.ACTIONS[\"clean\"]\n",
    "        \n",
    "        distance = 0\n",
    "        # Checar se tem algum chão sujo e pegar a distância, caso não tenha sujeira a distância sera 0.\n",
    "        for i in range(len(env.rooms)):\n",
    "            if env.rooms[i] == Enviroment.FLOOR_STATE[\"dirty\"]:\n",
    "                if abs(i - self.position) < abs(distance) or distance == 0:\n",
    "                    distance = i - self.position\n",
    "        \n",
    "        # Ir para direita se a distância for positiva, para esquerda se negativa e não fazer nada se distância for igual a zero.\n",
    "        decision = Agent.ACTIONS[\"right\"] if distance > 0 else Agent.ACTIONS[\"left\"] if distance < 0 else Agent.ACTIONS[\"NoOp\"]\n",
    "        \n",
    "        self.position += decision\n",
    "            \n",
    "        return decision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classe: Dumb_agent\n",
    "A classe Dumb_agent vai representar a ação do agente reativo simples em ambiente parcialmente observável"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dumb_agent(Agent):\n",
    "    def __init__ (self):\n",
    "        Agent.__init__(self)\n",
    "    \n",
    "    # Função que representa como o agente vai agir dado o ambiente\n",
    "    def action (self, env: Enviroment):\n",
    "        # Checar se a sala atual está suja e se estiver, limpar.\n",
    "        if env.rooms[self.position] == Enviroment.FLOOR_STATE[\"dirty\"]:\n",
    "            env.rooms[self.position] = Enviroment.FLOOR_STATE[\"clean\"]\n",
    "            \n",
    "            return Agent.ACTIONS[\"clean\"]\n",
    "        \n",
    "        # Decidir entre ir para esquerda ou direita de maneira aleatória com 50% de chande para cada lado.\n",
    "        decision = Agent.ACTIONS[\"right\"] if r.randint(0, 100) < 50 else Agent.ACTIONS[\"left\"]\n",
    "        # Verificar se bateu na parede, caso bater mudar decisão\n",
    "        if (decision == Agent.ACTIONS[\"left\"] and self.position == 0) or (decision == Agent.ACTIONS[\"right\"] and self.position == len(env.rooms) - 1):\n",
    "            decision = Agent.ACTIONS[\"NoOp\"]\n",
    "        \n",
    "        self.position += decision\n",
    "            \n",
    "        return decision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classe: Evaluator\n",
    "A classe evaluator vai representar a avaliação do agente no ambiente, foi criada com a intenção de funcionar para n passos(quantas iterações necessárias). Nessa classe foi implementada a lógica de pontuação do agente de acordo com suas ações(Dar 1 ponto sempre que limpar uma sala e perder 1 quando andar para direita ou esquerda)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator:\n",
    "    def __init__ (self, env: Enviroment, agent: Agent, steps: int, seed: int, dirtyRate: int):\n",
    "        self.env = env\n",
    "        self.agent = agent\n",
    "        self.steps = steps\n",
    "        r.seed(seed)\n",
    "        self.dirtyRate = dirtyRate\n",
    "        self.agent_points = 0\n",
    "    \n",
    "    # Função que inicia a simulação\n",
    "    def execute (self):\n",
    "        self.agent_points = 0\n",
    "        for i in range(self.steps):\n",
    "            # Pontuar o agente de acordo com a sua ação.\n",
    "            self.evaluate_agent(self.agent.action(self.env))\n",
    "            # Sujar sala de maneira aleatória.\n",
    "            self.env.rand_dirty_rooms(self.dirtyRate)\n",
    "        \n",
    "        return self.agent_points\n",
    "    \n",
    "    # Função que avalia o agente.\n",
    "    def evaluate_agent (self, action: int):\n",
    "        if action == Agent.ACTIONS[\"clean\"]:\n",
    "            self.agent_points += 1\n",
    "        elif action == Agent.ACTIONS[\"right\"] or action == Agent.ACTIONS[\"left\"]:\n",
    "            self.agent_points -= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rodando os testes\n",
    "Utilizando as classes para criar os testes pedidos para 2 salas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando as variáveis das classes.\n",
    "env = Enviroment(2)\n",
    "smart_agent = Smart_agent()\n",
    "dumb_agent = Dumb_agent()\n",
    "eval_smart = Evaluator(env, smart_agent, 1000, 123, 30)\n",
    "eval_dumb = Evaluator(env, dumb_agent, 1000, 123, 30)\n",
    "\n",
    "# Variáveis que representam os testes.\n",
    "env_possibilities = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "agent_possibilities = [0, 1]\n",
    "result_smart = []\n",
    "\n",
    "# Executando e printando os resultados.\n",
    "print(\"Agente Reativo Simples em Ambiente Completamente Observável:\")\n",
    "for agent_possibility in agent_possibilities:\n",
    "    print(f\"\\tPosição inicial {agent_possibility}: \")\n",
    "\n",
    "    for env_possibility in env_possibilities:\n",
    "        smart_agent.initial_position(agent_possibility)\n",
    "        env.init_rooms(env_possibility)\n",
    "        result_smart.append(eval_smart.execute())\n",
    "        print(f\"\\t\\tAmbiente inicial: {env_possibility} | Pontuação: {result_smart[-1]}\")\n",
    "        \n",
    "    print()\n",
    "print(f\"\\tMédia das pontuações: {sum(result_smart)/len(result_smart)}\")\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "result_dumb = []\n",
    "print(\"Agente Reativo Simples em Ambiente Parcialmente Observável:\")\n",
    "for agent_possibility in agent_possibilities:\n",
    "    print(f\"\\tPosição inicial {agent_possibility}: \")\n",
    "    \n",
    "    for env_possibility in env_possibilities:\n",
    "        dumb_agent.initial_position(agent_possibility)\n",
    "        env.init_rooms(env_possibility)\n",
    "        result_dumb.append(eval_dumb.execute())\n",
    "        print(f\"\\t\\tAmbiente inicial: {env_possibility} | Pontuação: {result_dumb[-1]}\")\n",
    "        \n",
    "    print()\n",
    "print(f\"\\tMédia das pontuações: {sum(result_dumb)/len(result_dumb)}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
