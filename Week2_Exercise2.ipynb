{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 2 - Agente Reativo Simples em Ambiente Completamente Observável"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implemente um novo agente reativo simples, mas agora com a vantagem de conhecer o ambiente (completamente observável). Você deve ser capaz de colocar o agente no seu simulador do exercício anterior e comparar o desempenho seguindo a mesma metodologia do exercício anterior. Compare o desempenho dos dois agentes (o deste exercício e o do anterior) neste simulador. Para o comparativo, alguns critérios do PEAS serão alterados.\n",
    "\n",
    "- **Medida de Desempenho**: A medida de desempenho oferece o prêmio de um ponto para cada quadrado limpo em cada período de tempo ao longo de uma duração de mil períodos de tempo. Entretanto, diferentemente do exercício anterior, agora penaliza em um ponto qualquer operação de movimento que não seja NoOp e Limpar.\n",
    "- **Conhecimento a priori**: A geografia do ambiente é conhecida a priori (Figura 2.2), mas a distribuição da sujeira e a posição inicial do agente não são previamente conhecidas. O ambiente para o agente é completamente observável. A aspiração limpa o quadrado atual. As ações esquerda e direita movem o agente para a esquerda e para a direita, exceto quando isso tenta levar o agente para fora do ambiente; nesse caso, o agente permanece onde está. \n",
    "- **Ações do agente**: Esquerda, Direita, Limpar e NoOp (fazer nada).\n",
    "- Percepções: O agente percebe corretamente sua posição e se esta posição contém sujeita.\n",
    "- **Ambiente**: mundo do aspirador de pó com apenas duas salas. Estas que por sua vez, podem estar limpas ou não conforme o tempo passa. A sujeira pode surgir de modo espontâneo para fins de simulação. \n",
    "\n",
    "Agora, implemente um agente reativo simples para este ambiente. Execute o simulador de ambiente com este agente para todas as configuraçoes iniciais possíveis de sujeira e posições do agente. Registre a pontuação  de desempenho dos dois agentes para cada configuração e suas pontuações médias globais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "Para começar vamos importar algumas funções que vamos utilizar no código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classe: Enviroment\n",
    "A classe Enviroment vai representar o ambiente, foi criada com a intenção de funcionar para n salas. Nessa classe foram implementadas as funções da criação do próprio ambiente e da criação de sujeira ao longo do tempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Enviroment:\n",
    "    FLOOR_STATE = {\"clean\": 0, \"dirty\": 1}\n",
    "    \n",
    "    def __init__ (self, size: int):\n",
    "        self.rooms = [0] * size\n",
    "    \n",
    "    # Função que inicia as salas de maneira randômica.\n",
    "    def init_randomly(self, dirtyRate: int):\n",
    "        for i in range(len(self.rooms)):\n",
    "            if r.randint(0, 100) < dirtyRate:\n",
    "                self.rooms[i] = Enviroment.FLOOR_STATE[\"dirty\"]\n",
    "            else:\n",
    "                self.rooms[i] = Enviroment.FLOOR_STATE[\"clean\"]\n",
    "    \n",
    "    # Função que inicia as salas de acordo com o array desejado.\n",
    "    def init_rooms(self, rooms: list):\n",
    "        self.rooms = rooms.copy()\n",
    "\n",
    "    # Função que suja as salas de maneira aleatória(usada no loop para sujar as salas de acordo com o tempo).\n",
    "    # dirtyRate: Variável que vai de 0 a 100 que representa a porcentagem de chance de sujar cada sala.\n",
    "    def rand_dirty_rooms (self, dirtyRate: int):\n",
    "        for i, room in enumerate(self.rooms):\n",
    "            if(room == Enviroment.FLOOR_STATE[\"clean\"] and r.randint(0, 100) < dirtyRate):\n",
    "                self.rooms[i] = Enviroment.FLOOR_STATE[\"dirty\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classe: Agent\n",
    "A classe agent representará o agente e possui a função que determina como o mesmo irá se comportar dado o ambiente. Ele possui as ações de NoOp(ficar pararo caso bater na parede), limpar(caso a sala que está esteja suja), direita e esquerda(para andar pelas salas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    ACTIONS = {\"NoOp\": 0, \"clean\": 2, \"right\": 1, \"left\": -1}\n",
    "    \n",
    "    def __init__ (self):\n",
    "        self.position = None\n",
    "        \n",
    "    def initial_position(self, initial_position: int):\n",
    "        self.position = initial_position\n",
    "    \n",
    "    def action (self, env: Enviroment):\n",
    "        if env.rooms[self.position] == Enviroment.FLOOR_STATE[\"dirty\"]:\n",
    "            env.rooms[self.position] = Enviroment.FLOOR_STATE[\"clean\"]\n",
    "            \n",
    "            return Agent.ACTIONS[\"clean\"]\n",
    "        \n",
    "        distance = 0\n",
    "        \n",
    "        for i in range(len(env.rooms)):\n",
    "            if env.rooms[i] == Enviroment.FLOOR_STATE[\"dirty\"]:\n",
    "                if abs(i - self.position) < abs(distance) or distance == 0:\n",
    "                    distance = i - self.position\n",
    "        \n",
    "        decision = Agent.ACTIONS[\"right\"] if distance > 0 else Agent.ACTIONS[\"left\"] if distance < 0 else Agent.ACTIONS[\"NoOp\"]\n",
    "            \n",
    "        self.position += decision\n",
    "            \n",
    "        return decision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classe: Evaluator\n",
    "A classe evaluator vai representar a avaliação do agente no ambiente, foi criada com a intenção de funcionar para n passos(quantas iterações necessárias). Nessa classe foi implementada a lógica de pontuação do agente de acordo com suas ações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator:\n",
    "    def __init__ (self, env: Enviroment, agent: Agent, steps: int, seed: int, dirtyRate: int):\n",
    "        self.env = env\n",
    "        self.agent = agent\n",
    "        self.steps = steps\n",
    "        r.seed(seed)\n",
    "        self.dirtyRate = dirtyRate\n",
    "        self.agent_points = 0\n",
    "    \n",
    "    # Função que inicia a simulação\n",
    "    def execute (self):\n",
    "        self.agent_points = 0\n",
    "        for i in range(self.steps):\n",
    "            # Pontuar o agente de acordo com a sua ação.\n",
    "            self.evaluate_agent(self.agent.action(self.env))\n",
    "            # Sujar sala de maneira aleatória.\n",
    "            self.env.rand_dirty_rooms(self.dirtyRate)\n",
    "        \n",
    "        return self.agent_points\n",
    "    \n",
    "    # Função que avalia o agente.\n",
    "    def evaluate_agent (self, action: int):\n",
    "        if action == Agent.ACTIONS[\"clean\"]:\n",
    "            self.agent_points += 1\n",
    "        elif action == Agent.ACTIONS[\"right\"] or action == Agent.ACTIONS[\"left\"]:\n",
    "            self.agent_points -= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rodando os testes\n",
    "Utilizando as classes para criar os testes pedidos para 2 salas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agente com posição inicial 0: \n",
      "\tAmbiente inicial: [0, 0] | Pontuação: 228\n",
      "\tAmbiente inicial: [0, 1] | Pontuação: 215\n",
      "\tAmbiente inicial: [1, 0] | Pontuação: 211\n",
      "\tAmbiente inicial: [1, 1] | Pontuação: 218\n",
      "\n",
      "Agente com posição inicial 1: \n",
      "\tAmbiente inicial: [0, 0] | Pontuação: 217\n",
      "\tAmbiente inicial: [0, 1] | Pontuação: 213\n",
      "\tAmbiente inicial: [1, 0] | Pontuação: 232\n",
      "\tAmbiente inicial: [1, 1] | Pontuação: 216\n",
      "\n",
      "Média das pontuações: 218.75\n"
     ]
    }
   ],
   "source": [
    "# Criando as variáveis das classes.\n",
    "env = Enviroment(2)\n",
    "agent = Agent()\n",
    "eval = Evaluator(env, agent, 1000, 123, 30)\n",
    "\n",
    "# Variáveis que representam os testes.\n",
    "env_possibilities = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "agent_possibilities = [0, 1]\n",
    "result = []\n",
    "\n",
    "for agent_possibility in agent_possibilities:\n",
    "    print(f\"Agente com posição inicial {agent_possibility}: \")\n",
    "    for env_possibility in env_possibilities:\n",
    "        agent.initial_position(agent_possibility)\n",
    "        env.init_rooms(env_possibility)\n",
    "        result.append(eval.execute())\n",
    "        print(f\"\\tAmbiente inicial: {env_possibility} | Pontuação: {result[-1]}\")\n",
    "    print()\n",
    "print(f\"Média das pontuações: {sum(result)/len(result)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
